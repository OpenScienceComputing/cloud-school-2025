{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120903d6-ea52-4a1e-83d2-4d434ad2cb98",
   "metadata": {},
   "source": [
    "# Creating and Appending to an Icechunk Store with Virtual References\n",
    "This notebook demonstrates how to create an icechunk store and then append to it.\n",
    "\n",
    "See this blog post for more info:  https://tom-nicholas.com/blog/2025/cloud-optimized-scientific-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69f0bb-316b-452c-b1ba-4d7ef4afcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import fsspec\n",
    "import icechunk\n",
    "import xarray as xr\n",
    "from obstore.store import from_url\n",
    "\n",
    "from virtualizarr import open_virtual_dataset\n",
    "from virtualizarr.parsers import HDFParser\n",
    "from virtualizarr.registry import ObjectStoreRegistry\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea109684-06bf-4845-a2e6-025fa3a02800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import virtualizarr\n",
    "print(icechunk.__version__)\n",
    "print(virtualizarr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191902e-6003-47ac-aa58-fa79c75269a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AWS credentials for Pangeo-EOSC storage as environment vars\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv(f'{os.environ['HOME']}/dotenv/rsignell4.env')\n",
    "\n",
    "# Define storage\n",
    "storage_endpoint = 'https://pangeo-eosc-minioapi.vm.fedcloud.eu'\n",
    "storage_bucket = 'rsignell4-protocoast'\n",
    "storage_name = 'taranto-icechunk-test2'\n",
    "\n",
    "fs = fsspec.filesystem('s3', anon=False, endpoint_url=storage_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df547e4-456d-44c1-b190-606f0b9e056e",
   "metadata": {},
   "source": [
    "### Create a list of files that will make up the virtual dataset\n",
    "First we will handle the \"nos\" SHYFEM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532c33b-804f-49fa-9fa9-0eb42ea87e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = fs.glob(f's3://{storage_bucket}/full_dataset/shyfem/taranto/forecast/*/*nos*.nc')\n",
    "flist = [f's3://{f}' for f in flist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85fd9db-82ba-4011-9f2d-9dae39d36ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(flist))\n",
    "print(flist[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734afd6-0224-4848-bd34-d16e9822835f",
   "metadata": {},
   "source": [
    "### Try opening one of these NetCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b507a-72d7-449a-beb0-7125dc0d1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(fs.open(flist[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f235fc4",
   "metadata": {},
   "source": [
    "### Define our Virtualizarr `Parser` and `ObjectStoreRegistry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"s3://rsignell4-protocoast\"\n",
    "store = from_url(bucket, region=\"not-used\", endpoint=storage_endpoint)\n",
    "registry = ObjectStoreRegistry({bucket: store})\n",
    "parser = HDFParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ceb93b-b0ac-48b2-928a-84da0d2019ac",
   "metadata": {},
   "source": [
    "## Create virtual datasets from each file with VirtualiZarr's `open_virtual_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbec92-3974-4859-8bda-353afc7800b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_list = [\n",
    "    open_virtual_dataset(\n",
    "        url=url,\n",
    "        parser=parser,\n",
    "        registry=registry,\n",
    "        loadable_variables=[\"time\"],\n",
    "    )\n",
    "    for url in flist[0:-1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417583db-d339-431b-88e4-f352b49ec09e",
   "metadata": {},
   "source": [
    "### \"fix\" each dataset to match the requirements of the \"Rolodex\" FMRC indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515578c-c9a9-43f8-8a7e-0e0439c7832e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ds(ds):\n",
    "    ds = ds.rename_vars(time='valid_time')\n",
    "    ds = ds.rename_dims(time='step')\n",
    "    step = (ds.valid_time - ds.valid_time[0]).assign_attrs({\"standard_name\": \"forecast_period\"})\n",
    "    time = ds.valid_time[0].assign_attrs({\"standard_name\": \"forecast_reference_time\"})\n",
    "    ds = ds.assign_coords(step=step, time=time)\n",
    "    ds = ds.drop_indexes(\"valid_time\")\n",
    "    ds = ds.drop_vars('valid_time')\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba5143-ca31-4c1f-bbae-26bb71ddd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = [fix_ds(ds) for ds in ds_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb94c8-870f-4c9e-8421-ac9c17402122",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_nos = xr.concat(\n",
    "    ds_list,\n",
    "    dim=\"time\",\n",
    "    coords=\"minimal\",\n",
    "    compat=\"override\",\n",
    "    combine_attrs=\"override\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd5234-2b10-4cfb-9ac9-8fda0afedc69",
   "metadata": {},
   "source": [
    "Now we handle the \"ous\" SHYFEM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf434316-dca2-42f9-94bb-513dc77838d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = fs.glob('s3://rsignell4-protocoast/full_dataset/shyfem/taranto/forecast/*/*ous*.nc')\n",
    "flist = [f's3://{f}' for f in flist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d7333-5df3-4c17-a6e6-3bcc2dd55682",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_list = [\n",
    "    open_virtual_dataset(\n",
    "        url=url,\n",
    "        parser=parser,\n",
    "        registry=registry,\n",
    "        loadable_variables=[\"time\"],\n",
    "    )\n",
    "    for url in flist[0:-1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a4d0b-6c90-4f2e-ac6b-70cefe9bb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ecee97-b228-44c8-bfb8-de21926a746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = [fix_ds(ds) for ds in ds_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f7552-6536-4d5d-a484-e672411498c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ous = xr.concat(\n",
    "    ds_list,\n",
    "    dim=\"time\",\n",
    "    coords=\"minimal\",\n",
    "    compat=\"override\",\n",
    "    combine_attrs=\"override\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60b6f8-abac-40c4-a124-d72409a3d55a",
   "metadata": {},
   "source": [
    "### Now create a virtual dataset with the \"nos\" and \"ous\" datasets merged together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab89408-8842-4963-b9d8-d6224a9923dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge([combined_nos, combined_ous], compat='override')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f41a0b-6292-419d-a9d3-d8ddf8c0c15b",
   "metadata": {},
   "source": [
    "## Initialize the Icechunk Store\n",
    "We need configure the `virtual_chunk_container` as make sure the icechunk container credentials allow for anonymous access. \n",
    "Details on this can be found [here](https://icechunk.io/en/stable/virtual/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e8eea-655c-4fc9-84a5-e0d27e8d4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove old existing icechunk storage with this name\n",
    "try:\n",
    "    # Use the same prefix as the storage\n",
    "    fs.rm(f's3://{storage_bucket}/icechunk/{storage_name}', recursive=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc24a3-3beb-451e-b0ef-8db8fda5a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = icechunk.s3_storage(\n",
    "    bucket=storage_bucket,\n",
    "    prefix=f\"icechunk/{storage_name}\",\n",
    "    from_env=True,\n",
    "    endpoint_url=storage_endpoint,\n",
    "    region='not-used',   # N/A for Pangeo-EOSC bucket, but required param\n",
    "    force_path_style=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4228a-0e17-4b07-9144-f24fe06db832",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = icechunk.RepositoryConfig.default()\n",
    "\n",
    "config.set_virtual_chunk_container(\n",
    "    icechunk.VirtualChunkContainer(\n",
    "        url_prefix=f\"s3://{storage_bucket}/\",\n",
    "        store=icechunk.s3_store(region=\"not-used\", anonymous=False, s3_compatible=True, \n",
    "                                force_path_style=True, endpoint_url=storage_endpoint),\n",
    "    ),\n",
    ")\n",
    "\n",
    "repo = icechunk.Repository.create(storage, config)\n",
    "session = repo.writable_session(\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749193c1-38b9-4400-a08f-f0a675d30f06",
   "metadata": {},
   "source": [
    "## Write the virtual datasets to the icechunk store and commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9387e1ff-46c1-45fd-9796-0457538209a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.virtualize.to_icechunk(session.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a74fb9-006b-4d2b-9157-7090af6c9e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.commit(\"all but last day of Taranto data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becd176-1c7d-4c74-a3f1-1b9f55b445a2",
   "metadata": {},
   "source": [
    "## Check the icechunk dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae141bd7-8227-43d9-861b-812ff7e482c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = icechunk.containers_credentials(\n",
    "    {f\"s3://{storage_bucket}/\": icechunk.s3_credentials(anonymous=False)})\n",
    "\n",
    "read_repo = icechunk.Repository.open(\n",
    "    storage, config, authorize_virtual_chunk_access=credentials)\n",
    "\n",
    "read_session = read_repo.readonly_session(\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6271bd1-bc0b-4901-9901-91aabe508cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(read_session.store, consolidated=False, zarr_format=3)\n",
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo_z3]",
   "language": "python",
   "name": "conda-env-pangeo_z3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
