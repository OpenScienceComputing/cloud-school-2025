{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring data interoperability with STAC and the Microsoft Planetary Computer\n",
    "\n",
    "By [Pete Gadomski](https://github.com/gadomski).\n",
    "\n",
    "## Discovery\n",
    "\n",
    "First, let's find out what collections are available to us on the Planetary Computer.\n",
    "We'll use [pystac-client](https://pystac-client.readthedocs.io/en/stable/) to query the Planetary Computer's [STAC API](https://github.com/radiantearth/stac-api-spec)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from rich.table import Table\n",
    "\n",
    "PLANETARY_COMPUTER = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "client = Client.open(PLANETARY_COMPUTER)\n",
    "collections = list(client.get_all_collections())\n",
    "collections.sort(key=lambda c: c.id)\n",
    "table = Table(\"ID\", \"Title\", title=\"Planetary Computer collections\")\n",
    "for collection in collections:\n",
    "    table.add_row(collection.id, collection.title)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our Landsat collection id\n",
    "\n",
    "As you can see, there's a ton of collections.\n",
    "Because this is PECORA, let's narrow in on the [Landsat](https://landsat.gsfc.nasa.gov/) collections for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.markdown import Markdown\n",
    "\n",
    "landsat_collections = [c for c in collections if c.id.startswith(\"landsat\")]\n",
    "table = Table(\"ID\", \"Title\", \"Description\",\n",
    "              title=\"Planetary Computer Landsat collections\")\n",
    "for collection in landsat_collections:\n",
    "    table.add_row(collection.id,\n",
    "                  collection.title,\n",
    "                  Markdown(collection.description))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the correct Landsat collection\n",
    "\n",
    "As you can see, there's currently three Landsat collections in the Planetary Computer.\n",
    "Which one to use?\n",
    "The two `landsat-c2-*` collections seem to be of a pair, but what's going on with `landsat-8-c2-l2`?\n",
    "\n",
    "Turns out that `landsat-8-c2-l2` is an old collection that has been superseded by `landsat-c2-l2`.\n",
    "There's no way to know this from the STAC metadata, though we (being the Planetary Computer team) should probably fix that by marking it deprecated with the [version extension](https://github.com/stac-extensions/version).\n",
    "The deprecated collection is hidden from the website interface, if you use that.\n",
    "\n",
    "But, for now, we'll use `landsat-c2-l2` for Landsat Level 2 data.\n",
    "\n",
    "# Fetching and displaying data\n",
    "\n",
    "First, let's demonstrate loading data using **pystac-client** and [odc-stac](https://github.com/opendatacube/odc-stac).\n",
    "**odc-stac** is part of the [OpenDataCube](https://www.opendatacube.org/), ecosystem, but stands alone as its own software package.\n",
    "If you're familiar with OpenDataCube, you know that it's primary product is a database-cum-analysis software stack used for analyzing geospatial data, not dissimilar to the Planetary Computer.\n",
    "**odc-stac** represents a coming together between the OpenDataCube and the STAC ecosystems, because it take STAC items and turns them into analysis-ready xarrays using routines developed for the OpenDataCube.\n",
    "**odc-stac** *does not* require a database, or any significant dependencies.\n",
    "\n",
    "We'll define an area around Steamboat Springs, Colorado, and a datetime range during the winter.\n",
    "We'll also search for items that have a sufficiently low amount enough of cloud cover to create a good mosaic.\n",
    "First, let's find the STAC items that match our criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSAT_COLLECTION = \"landsat-c2-l2\"\n",
    "# this is a simplified datetime syntax that pystac-client understands\n",
    "DATETIME = \"2022-06\"\n",
    "CLOUD_COVER_THRESHOLD = 10  # percent\n",
    "BBOX = [-107.381493, 40.118423, -106.331366, 40.960106]  # Steamboat Springs, CO\n",
    "\n",
    "item_search = client.search(\n",
    "    collections=[LANDSAT_COLLECTION],\n",
    "    bbox=BBOX,\n",
    "    datetime=DATETIME,\n",
    "    query=[f\"eo:cloud_cover<={CLOUD_COVER_THRESHOLD}\"],\n",
    ")\n",
    "item_collection = item_search.item_collection()\n",
    "print(f\"Found {len(item_collection)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the STAC footprints\n",
    "\n",
    "So far, we've only fetched STAC metadata, which are just JSON objects.\n",
    "We haven't fetched any raster data at all.\n",
    "How do the footprints of our STAC items relate to our bounding box of interest?\n",
    "Let's look, using **folium**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import Map, GeoJson\n",
    "from shapely.geometry import box\n",
    "\n",
    "item_style_function = lambda s: {\n",
    "    \"color\": \"#8da0cbaa\"\n",
    "}\n",
    "bbox_style_function = lambda s: {\n",
    "    \"color\": \"#fc8d62\"\n",
    "}\n",
    "\n",
    "map = Map(tiles=\"OpenStreetMap\")\n",
    "minx = 180\n",
    "maxx = -180\n",
    "miny = 90\n",
    "maxy = -90\n",
    "for item in item_collection:\n",
    "    if item.bbox[0] < minx:\n",
    "        minx = item.bbox[0]\n",
    "    if item.bbox[1] < miny:\n",
    "        miny = item.bbox[1]\n",
    "    if item.bbox[2] > maxx:\n",
    "        maxx = item.bbox[2]\n",
    "    if item.bbox[3] > maxy:\n",
    "        maxy = item.bbox[3]\n",
    "    GeoJson(item.to_dict(), style_function=item_style_function).add_to(map)\n",
    "GeoJson(box(*BBOX), style_function=bbox_style_function).add_to(map)\n",
    "map.fit_bounds([[miny, minx], [maxy, maxx]])\n",
    "display(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data only in our area of interest\n",
    "\n",
    "As you can see, the item bounds extend well beyond our bounding box of interest.\n",
    "While we could load all the data from all items, that's inefficient.\n",
    "**odc-stac** can use our bounding box and the fact that our Landsat data is stored as Cloud-Optimized GeoTIFFs (COGs) to only read the bits we need, not all of the data.\n",
    "Let's show that in action, loading only the RGB bands for quick visualization.\n",
    "Note that we use the Planetary Computer API to sign the asset hrefs, which appends a Shared Access Signature (SAS) to allow access to the data assets.\n",
    "\n",
    "We load the data at 100m resolution to speed up display operations.\n",
    "For analysis, you'll most likely want to load at native resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.stac\n",
    "import planetary_computer\n",
    "\n",
    "item_collection = planetary_computer.sign_item_collection(item_collection)\n",
    "data = odc.stac.load(\n",
    "    item_collection,\n",
    "    bands=[\"red\", \"green\", \"blue\"],\n",
    "    groupby=\"solar_day\",\n",
    "    bbox=BBOX,\n",
    "    resolution=100\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting RGB data\n",
    "\n",
    "There's nothing better than visualizing your data as full-color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_data = data.odc.to_rgba(vmin=1, vmax=15000, bands=[\"red\", \"green\", \"blue\"])\n",
    "rgb_data.plot.imshow(col=\"time\", rgb=\"band\", robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly composite using dask\n",
    "\n",
    "This is all pretty easy work, and works moderatly well when running in a synchronous execution environment.\n",
    "However, when trying to scale up this type of work into large spatial and temporal domains, some problems are easily parallelizable.\n",
    "[Dask](https://www.dask.org/) is a powerful parallel execution enviornment that works well in single-user, large data environments, such as geospatial analysis.\n",
    "The Planetary Computer Hub includes a Dask Gateway cluster for use for analysis; you can also set up Dask Gateway using [local processes](https://gateway.dask.org/install-local.html), e.g. on your laptop.\n",
    "\n",
    "First, let's set up a gateway cluster.\n",
    "You can click on the dashboard link to see the execution status of the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_type = 'Coiled'\n",
    "#cluster_type = 'Gateway'\n",
    "#cluster_type = 'Local'\n",
    "cluster_type = 'Local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_type == 'Coiled':\n",
    "    import coiled\n",
    "    cluster = coiled.Cluster(\n",
    "        region=\"us-west-2\",\n",
    "        arm=True,   # run on ARM to save energy & cost\n",
    "        worker_vm_types=[\"t4g.small\"],  # cheap, small ARM instances, 2cpus, 2GB RAM\n",
    "        worker_options={'nthreads':2},\n",
    "        n_workers=30,\n",
    "        wait_for_workers=False,\n",
    "        compute_purchase_option=\"spot_with_fallback\",\n",
    "        name='landsat',   # Dask cluster name\n",
    "        software='protocoast-develop-arm',  # Conda environment name\n",
    "        workspace='osc-aws',\n",
    "        timeout=180   # leave cluster running for 3 min in case we want to use it again\n",
    "    )\n",
    "\n",
    "    dask_client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_type == 'Gateway':\n",
    "    from dask_gateway import Gateway\n",
    "    import os\n",
    "    gateway = Gateway()\n",
    "  # Set Dask Gateway cluster options \n",
    "    options = gateway.cluster_options()\n",
    "    options.image = os.environ['JUPYTER_IMAGE']   # set worker image same as notebook\n",
    "    print('Setting Cluster Image',options.image) \n",
    "    # Now start a new cluster which has these options\n",
    "    print('Starting new cluster.')\n",
    "    cluster = gateway.new_cluster(options)   \n",
    "    cluster.adapt(minimum=4, maximum=24)\n",
    "    dask_client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_type == 'Local':\n",
    "    from dask.distributed import LocalCluster\n",
    "    from dask.distributed import Client as DaskClient\n",
    "    cluster = LocalCluster()\n",
    "    dask_client = DaskClient(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's find images for the same area of interest, but this time for the whole year of 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_search = client.search(\n",
    "    collections=[LANDSAT_COLLECTION],\n",
    "    bbox=BBOX,\n",
    "    datetime=\"2021\",\n",
    "    query=[f\"eo:cloud_cover<=25\"],\n",
    ")\n",
    "item_collection = planetary_computer.sign_item_collection(item_search.item_collection())\n",
    "print(f\"Found {len(item_collection)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the `chunks` option to `odc.stac.load`, we instruct **odc-stac** to break up the data loading into a set of tasks, which will be fanned out to Dask workers on request.\n",
    "Note that we haven't actually loaded any data yet; we've only built the execution graph, or plan.\n",
    "Your Dask gateway status page should be still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = odc.stac.load(\n",
    "    item_collection,\n",
    "    bands=[\"red\", \"green\", \"blue\"],\n",
    "    bbox=BBOX,\n",
    "    resolution=100,\n",
    "    groupby=\"solar_day\",\n",
    "    chunks={\"x\": 2048, \"y\": 2048},\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By asking our xarray to persist its data, we now actually load the data into our xarray on our workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create monthly composites of the band data, which will be done on the Dask cluster as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "monthly_data = data.groupby(\"time.month\").median().compute()\n",
    "monthly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's display!\n",
    "We could do a lot more to create better composities, but we'll leave that as an exercise for the reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data_rgb = monthly_data.odc.to_rgba(vmin=1, vmax=15000, bands=[\"red\", \"green\", \"blue\"])\n",
    "monthly_data_rgb.plot.imshow(x=\"x\", y=\"y\", rgb=\"band\", col=\"month\", col_wrap=3, figsize=(6, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "df876230d2adcf765a386c82af6ae06d07dba12c4370aedc8f5becd8c1272046"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
